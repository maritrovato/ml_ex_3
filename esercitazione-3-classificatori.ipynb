{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Esercitazione 3 - Classificatori: Regressione Logistica e SVM**\n\nIn questa esercitazione applicheremo quanto appreso sui classificatori. Nello specifico utilizzeremo:\n\n* **Regressione Logistica:** Un modello lineare che utilizza la funzione sigmoide per predire le probabilità delle classi.\n\n* **Support Vector Machines (SVM):** Efficace sia per problemi lineari che non lineari utilizzando il kernel trick.","metadata":{}},{"cell_type":"markdown","source":"### **Dataset MNIST-784**\n\nIl dataset di riferimento sarà `MNIST-784`, già visto in precedenza. Il dataset contiene immagini di 10 classi (da 0 a 9). Per comodità utilizzeremo soltanto 2 classi inizialmente, per rendere la classificazione binaria. Nello specifico utilizzeremo soltanto le immagini che hanno come etichetta `3` e `8`. \n\nIl codice seguente esegui l' import delle librerie necessarie e la selezione delle etichette che ci interessano. Le etichette vengono anche rimpiazzate con `1` e `0`, emulando il caso di classificazione binaria.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.814826Z","iopub.status.idle":"2025-04-05T12:57:57.815302Z","shell.execute_reply":"2025-04-05T12:57:57.815088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mnist = fetch_openml('mnist_784', version=1, parser='auto')\nX, y = mnist.data, mnist.target.astype(int)\n\nindexes = (y == 3) | (y == 8)\nX = X[indexes]  \ny = y[indexes]\n\ny = np.where(y == 8, 1, 0)\n\nprint(f\"Features shape: {X.shape}, Labels shape: {y.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.816406Z","iopub.status.idle":"2025-04-05T12:57:57.816830Z","shell.execute_reply":"2025-04-05T12:57:57.816646Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Divisione e standardizzazione del dataset** \n\nDividiamo il dataset in `train set`, `validation set` e `test set` utilizzando le proporzioni già impostate. Successivamente applichiamo la standardizzazione utilizzando `StandardScaler`.","metadata":{}},{"cell_type":"code","source":"# Usare le seguenti proporzioni per il train, validation e test\ntrain_fraction = 0.6  \nvalidation_fraction = 0.2  \ntest_fraction = 0.2\n\n# svolgimento...\nnum_train = int(train_fraction * X.shape[0])\nnum_validation = int(validation_fraction * X.shape[0])\nX_train = X[:num_train]\ny_train = y[:num_train]\nX_validation = X[num_train:num_train + num_validation]\ny_validation = y[num_train:num_train + num_validation]\nX_test = X[num_train + num_validation:]\ny_test = y[num_train + num_validation:]\n\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_validation = scaler.transform(X_validation)\nX_test = scaler.transform(X_test)\n\nprint(f\"Train set: {X_train.shape}\")\nprint(f\"Validation set: {X_validation.shape}\")\nprint(f\"Test set: {X_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.817706Z","iopub.status.idle":"2025-04-05T12:57:57.818152Z","shell.execute_reply":"2025-04-05T12:57:57.817959Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Esercizio 1: Implementare la Regressione Logistica**\n\nPer implementare la regressione logistica utilizzeremo la classe `sklearn.linear_model.LogisticRegression` presente in `scikit-learn`. La documentazione è disponibile [a questo link](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n\nPer utilizzarla al meglio, di seguito vediamo i parametri chiave che bisogna specificare al momento della creazione dell' istanza:\n\n* **`C`**: Inverso della forza di regolarizzazione L2 (λ). Valori più piccoli indicano una regolarizzazione più forte.\n* **`solver`**: Algoritmo da utilizzare nel problema di ottimizzazione (nel nostro caso, `liblinear`).\n* **`max_iter`**: Imposta il numero massimo di iterazioni affinché l'algoritmo di ottimizzazione converga e trovi i migliori parametri del modello.\n\n### Esempio di sintassi per istanziare, addestrare e predire\n\n```python\n#Importo LogisticRegression da scikit-learn\nfrom sklearn.linear_model import LogisticRegression\n\n#1. Instanzio il modello di Regressione Logistica\n# Durante la creazione dell' istanza imposto i parametri che desidero\nmodel = LogisticRegression(max_iter=100, solver='liblinear',C=1.0)\n\n#2. Train del modello utilizzando il metodo .fit()\nmodel.fit(X_train, y_train)\n\n#3. Calcolo delle predizioni utilizzando il metodo .predict()\npredictions = model.predict(X_test)\n\n```","metadata":{}},{"cell_type":"markdown","source":"### **Guida per la risoluzione**\n\nDi seguito sono spiegati i passaggi principali per la risoluzione dell' esercizio.\n\n1. **Creazione del modello:** Creare un' istanza della classe `LogisticRegression`, specificando i parametri presentati poco sopra. In particolare vogliamo i seguenti parametri:\n    \n    - `max_iter` = 100\n    - `solver` = `'liblinear'`\n    - `C` = 1.0\n\n2. **Addestramento del modello:** Addestriamo il modello utilizzando il metodo `.fit()`. Il modello deve essere addestrato sui dati di train standardizzati. \n\n3. **Calcolo delle predizioni:** Calcoliamo le predizioni sul validation e test utilizzando il metodo `.predict()` del modello. \n\n4. **Valutazione delle prestazioni del modello:** Calcoliamo l' accuracy del modello. Ricordiamo che l' accuracy è data dal numero di predizioni corrette che il modello effettua rispetto al totale dei campioni. Dobbiamo valutare il modello sia sul validation set che sul test set. Infine stampare il valore di accuracy sul validation e sul test.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nimport numpy as np\n\n# Step 1 - Creazione del modello\n\n# svolgimento...\nmodello = LogisticRegression(max_iter = 100, solver = 'liblinear', C = 1.0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.819089Z","iopub.status.idle":"2025-04-05T12:57:57.819535Z","shell.execute_reply":"2025-04-05T12:57:57.819346Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2 - Addestramento del modello\n\n# svolgimento...\nmodello.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.820515Z","iopub.status.idle":"2025-04-05T12:57:57.820885Z","shell.execute_reply":"2025-04-05T12:57:57.820756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3 - Calcolo delle predizioni\n\n# svolgimento...\npredizioni_val = modello.predict(X_validation)\npredizioni_test = modello.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.822255Z","iopub.status.idle":"2025-04-05T12:57:57.822595Z","shell.execute_reply":"2025-04-05T12:57:57.822474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4 - Calcolo delle metriche di valutazione\n\n# svolgimento...\ncorrect_val = np.sum(y_validation == predizioni_val )\ntotal_val = len(y_validation)\nacc_val = correct_val / total_val if total_val > 0 else 0\n\ncorrect_test = np.sum(y_test == predizioni_test)\ntotal_test =len(y_test)\nacc_test = correct_test / total_test if total_test > 0 else 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.823420Z","iopub.status.idle":"2025-04-05T12:57:57.823808Z","shell.execute_reply":"2025-04-05T12:57:57.823624Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Esercizio 2: Implementare Support Vector Machines (SVM)**\n\nPer implementare le SVM utilizziamo la classe `sklearn.svm.SVC` presente in `scikit-learn`. La documentazione è disponibile [a questo link](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n\nPer utilizzarla al meglio, di seguito vediamo i parametri chiave che bisogna specificare al momento della creazione dell' istanza:\n\n* **`C`**: Parametro di regolarizzazione. L'intensità della regolarizzazione è inversamente proporzionale a C.\n* **`kernel`**: Specifica il tipo di kernel da utilizzare nell'algoritmo (`'linear'`, `'poly'`, `'rbf'`).\n\n### Esempio di sintassi per istanziare, addestrare e predire\n\n```python\n#Importare la classe SVC da scikit-learn\nfrom sklearn.svm import SVC\n\n#1. Creare un' istanza della classe SVC\n# Durante la creazione dell' istanza imposto i parametri che desidero\nmodel = SVC(kernel='linear', C=1.0)\n\n#2. Train del modello utilizzando il metodo .fit()\nmodel.fit(X_train, y_train)\n\n#3. Calcolo delle predizioni utilizzando il metodo .predict()\npredictions = model.predict(X_test)","metadata":{}},{"cell_type":"markdown","source":"### **C** in SVM:\n\n**C** è una penalità per i punti classificati erroneamente.\n\n- **Small C**: Margine più ampio, tollera alcuni errori (rischio di underfitting).\n- **Large C**: Minimizza gli errori, margine più stretto (rischio di overfitting).","metadata":{}},{"cell_type":"markdown","source":"### **Guida per la risoluzione**\n\nDi seguito sono spiegati i passaggi principali per la risoluzione dell' esercizio.\n\n1. **Creazione del modello:** Creare un' istanza della classe `SVC`, specificando i parametri presentati poco sopra. In particolare vogliamo i seguenti parametri:\n    \n    - `kernel` = `'linear'`\n    - `C` = 0.01\n\n2. **Addestramento del modello:** Addestriamo il modello utilizzando il metodo `.fit()`. Il modello deve essere addestrato sui dati di train standardizzati. \n\n3. **Calcolo delle predizioni:** Calcoliamo le predizioni sul validation e test utilizzando il metodo `.predict()` del modello. \n\n4. **Valutazione delle prestazioni del modello:** Calcoliamo l' accuracy del modello. Ricordiamo che l' accuracy è data dal numero di predizioni corrette che il modello effettua rispetto al totale dei campioni. Dobbiamo valutare il modello sia sul validation set che sul test set. Infine stampare il valore di accuracy sul validation e sul test.","metadata":{}},{"cell_type":"code","source":"# Step 1 - Creazione del modello\nfrom sklearn.svm import SVC\nimport numpy as np\n\n# svolgimento...\nmodel = SVC(kernel = 'linear', C = 0.01)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.824535Z","iopub.status.idle":"2025-04-05T12:57:57.824836Z","shell.execute_reply":"2025-04-05T12:57:57.824714Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2 - Addestramento del modello\n\n# svolgimento...\nmodel.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.825539Z","iopub.status.idle":"2025-04-05T12:57:57.825919Z","shell.execute_reply":"2025-04-05T12:57:57.825721Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3 - Calcolo delle predizioni\n\n# svolgimento...\ntest_predizioni= model.predict(X_test)\nval_predizioni= model.predict(X_validation)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.826897Z","iopub.status.idle":"2025-04-05T12:57:57.827296Z","shell.execute_reply":"2025-04-05T12:57:57.827082Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4 - Calcolo delle metriche di valutazione\n\n# svolgimento...\nval_correct = sum(val_predizioni == y_validation)\ntest_correct = sum(test_predizioni == y_test)\n\ntot_val = len(y_validation)\ntot_test = len(y_test)\n\nval_acc = val_correct / tot_val if tot_val > 0 else 0\ntest_acc = test_correct / tot_test if tot_test > 0 else 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.828317Z","iopub.status.idle":"2025-04-05T12:57:57.828700Z","shell.execute_reply":"2025-04-05T12:57:57.828524Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Esercizio 2.1: Implementare SVM con kernel trick**\n\nVogliamo implementare un classificatore SVM che utilizza il kernel-trick. Le linee guida sono esattamente quanto fatto prima, dobbiamo però modificare il tipo di kernel del modello. Per utilizzare il kernel trick usiamo un **kernel a base radiale (Radial Basis Function)** specificando il parametro:\n\n- `kernel` = `'rbf'`","metadata":{}},{"cell_type":"code","source":"# Step 1 - Creazione del modello\nfrom sklearn.svm import SVC\nimport numpy as np\n\n# svolgimento...\nmodel = SVC(kernel = 'rbf', C = 0.01)\n\n# Step 2 - Addestramento del modello\n\n# svolgimento...\nmodel.fit(X_train, y_train)\n\n# Step 3 - Calcolo delle predizioni\n\n# svolgimento...\ntest_predizioni = model.predict(X_test)\nval_predizioni = model.predict(X_validation)\n\n# Step 4 - Calcolo delle metriche di valutazione\n\n# svolgimento...\nval_correct = sum(val_predizioni == y_validation)\ntest_correct = sum(test_predizioni == y_test)\n\ntot_val = len(y_validation)\ntot_test = len(y_test)\n\nval_acc = val_correct / tot_val if tot_val > 0 else 0\ntest_acc = test_correct / tot_test if tot_test > 0 else 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.830005Z","iopub.status.idle":"2025-04-05T12:57:57.830490Z","shell.execute_reply":"2025-04-05T12:57:57.830281Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Esercizio 3: Metriche di valutazione**\n\n**Matrice di confusione:** \n\nLa matrice di confusione (anche nota come `confusion matrix` ) è una tabella che riassume le prestazioni di un modello di classificazione mostrando i conteggi dei veri positivi (TP), veri negativi (TN), falsi positivi (FP) e falsi negativi (FN). In questo codice, per un problema di classificazione binaria con classi 0 e 1, la `confusion matrix` è strutturata come segue:\n\n|                | **Predicted Class 0** | **Predicted Class 1** |\n|----------------|:------------------------:|:------------------------:|\n| **Actual Class 0** | TN                     | FP                     |\n| **Actual Class 1** | FN                     | TP                     |\n\n* **TN (True Negatives):** Il numero di istanze che erano effettivamente Classe 0 e sono state correttamente previste come Classe 0.\n\n* **FP (False Positives):** Il numero di istanze che erano effettivamente Classe 0 ma sono state erroneamente previste come Classe 1.\n\n* **FN (False Negatives):** Il numero di istanze che erano effettivamente Classe 1 ma sono state erroneamente previste come Classe 0.\n\n* **TP (True Positives):** Il numero di istanze che erano effettivamente Classe 1 e sono state correttamente previste come Classe 1.\n\n\n* **Accuracy:** Misura la correttezza complessiva del modello. È il rapporto tra le istanze correttamente classificate e il numero totale di istanze.\n\n    $$\n    \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n    $$\n\n* **Precision:** Misura l'accuratezza delle previsioni positive. È il rapporto tra le istanze positive correttamente previste e il numero totale di istanze previste come positive.\n\n    $$\\text{Precision} = \\frac{TP}{TP + FP}$$\n\n* **Recall (Sensitivity or True Positive Rate):** Misura la capacità del modello di trovare tutte le istanze positive. È il rapporto tra le istanze positive correttamente previste e il numero totale di vere istanze positive.\n\n    $$\\text{Recall} = \\frac{TP}{TP + FN}$$\n\n* **F1-Score:** La media armonica di precisione e richiamo. Fornisce un punteggio unico che bilancia sia la precisione che il richiamo, particolarmente utile quando c'è una distribuzione asimmetrica delle classi.\n\n    $$\\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$","metadata":{}},{"cell_type":"markdown","source":"Per calcolare le metriche utilizziamo le funzioni presenti in `sklearn.metrics`:\n\n#### `confusion_matrix`\n\nDati in input il target reale e le predizioni calcola la matrice di confusione. Documentazione disponibile al seguente link [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html).\n\n**Syntax**:\n```python\nconfusion_matrix(y_true, y_pred)\n```\n\n#### `classification_report`\n\nGenera un report testuale che mostra le principali metriche di classificazione. Documentazione disponibile al seguente link [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html).\n\n**Syntax**:\n```python\nclassification_report(y_true, y_pred)\n```\n\n#### `precision_score`\n\nMisura il rapporto tra le istanze positive correttamente previste e il totale delle previsioni positive. Documentazione disponibile al seguente link [precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html).\n\n**Syntax**:\n```python\nprecision_score(y_true, y_pred, average='binary')\n```\n\n#### `recall_score`\n\nMisura il rapporto tra le istanze positive correttamente previste e il totale delle istanze positive effettive. Documentazione disponibile al seguente link [recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n\n**Syntax**:\n```python\nrecall_score(y_true, y_pred, average='binary')\n```\n\n#### `f1_score`\n\nCalcola la media armonica di precision e recall. Documentazione disponibile al seguente link [f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n\n**Syntax**:\n```python\nf1_score(y_true, y_pred, average='binary')\n```\n\n","metadata":{}},{"cell_type":"markdown","source":"### **Guida:**\n\n1. **Calcoliamo la matrice di confusione:** Calcolare la matrice di confusione con `confusion_matrix` e stamparla.\n\n2. **Calcoliamo precision, recall e F1 score:** Calcolare le metriche di valutazione con le funzioni presentate sopra e stamparle.\n\n3. **Calcoliamo il classification report:** Calcolare il classification report e stamparlo.\n\n4. **Stampare la matrice di confusione:** Utilizzare la funzione `plot_confusion_matrix` che vi abbiamo fornito per stampare la matrice di confusione. La funzione ha bisogno di un unico parametro che è la matrice di confusione calcolata al punto 1.","metadata":{}},{"cell_type":"code","source":"# Step 1 - Calcolare la matrice di confusione\n\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# svolgimento...\nmatrice_val = confusion_matrix(y_validation, predizioni_val)\nmatrice_tes = confusion_matrix(y_test, predizioni_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.831566Z","iopub.status.idle":"2025-04-05T12:57:57.832014Z","shell.execute_reply":"2025-04-05T12:57:57.831814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2 - Calcolare precision, recall e F1 score\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# svolgimento...\nprecision_val = precision_scaler(y_validation, predizioni_val, avarage = 'binary')\nprecision_test = precision_score(y_validation, predizioni_test, avarage = 'binary'\n                          )\nrecall_val= recall_score(y_validation, predizioni_val, avarage = 'binary')\nrecall_test= recall_score(y_test, predizioni_test, avarage = 'binary')\nf1_val = f1_score(y_validation, predizioni_val, avarage = 'binary')\nf1_test = fi_score(y_validation, predizioni_test, avarage = 'binary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.832860Z","iopub.status.idle":"2025-04-05T12:57:57.833327Z","shell.execute_reply":"2025-04-05T12:57:57.833117Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3 - Calcolare il report di classificazione\nfrom sklearn.metrics import classification_report\n\n# svolgimento...\nclass_val = classification_report(y_validation, predizioni_val)\nclass_test = classification_report(y_test, predizioni_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.834565Z","iopub.status.idle":"2025-04-05T12:57:57.835007Z","shell.execute_reply":"2025-04-05T12:57:57.834808Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4 - Visualizzare la matrice di confusione\n\ndef plot_confusion_matrix(cm):\n    \"\"\"\n    Visualizza una matrice di confusione come heatmap.\n    \n    Parameters:\n    -----------\n    cm : numpy.ndarray\n        La matrice di confusione da visualizzare\n    \"\"\"\n    plt.figure(figsize=(6, 4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n# svolgimento...\nplot_confusion_matrix(matrice_val)\nplot_confusion_matrix(matrice_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.835801Z","iopub.status.idle":"2025-04-05T12:57:57.836265Z","shell.execute_reply":"2025-04-05T12:57:57.836050Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **ROC Curve, AUC**\n\nPer calcolare la ROC curve, e conseguentemente l' AUC, abbiamo bisogno delle probabilità di predizione. \n\nNel caso della **regressione logistica** possiamo utilizzare l' attributo del modello `predict_proba` da utilizzare come segue:\n\n```python\n# Estrai le probabilità della classe positiva\ny_pred_proba = classifier.predict_proba(X_test_scaled)[:, 1]\n```\n\nPer quanto riguarda invece l' **SVM**, è necessario specificare il parametro `probability` = **True** affinchè `predict_proba` funzioni.\n\n```python\n# Specifica il parametro probability=True \nclassifier = SVC(kernel='linear', C=0.01, probability=True)\n```\n\nUna volta estratte le probabilità possiamo utilizzare le funzione di `sklearn.metrics`:\n\n- `roc_curve` \n- `roc_auc_score`\n\nDi seguito è mostrata la sintassi per utilizzare le due funzioni.\n\n---\n\n#### `roc_curve`\n```python\n# Calcola i valori della curva ROC\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n```\nCalcola i valori della Curva ROC (Receiver Operating Characteristic): Tasso di Falsi Positivi (FPR), Tasso di Veri Positivi (TPR) e soglie.\n\n---\n\n#### `roc_auc_score`\n```python\n# Calcola AUC\nauc = roc_auc_score(y_test, y_pred_proba)\n```\nCalcola l'Area Under the Curve (AUC) per la ROC, quantificando la capacità del modello di distinguere tra classi positive e negative.","metadata":{}},{"cell_type":"code","source":"# Step 1 - Estrarre le probabilità dal modello di regressione logistica\n# ATTENZIONE: Per il calcolo della ROC curve ci servono le probabilità della classe positiva.\n\n# svolgimento...\ny_pred_prob_reg = modello.predict_proba(X_test)[:,1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.837410Z","iopub.status.idle":"2025-04-05T12:57:57.837848Z","shell.execute_reply":"2025-04-05T12:57:57.837658Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2 - Allenare l' SVM con il parametro probability=True ed estrarre le probabilità\n\n# svolgimento...\nmodello = SVC(kernel = 'linear', C = 0.01, probability = True)\nmodello.fit(X_train, y_train)\ny_pred_proba_svm = modello.predict_proba(X_test)[:,1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.839093Z","iopub.status.idle":"2025-04-05T12:57:57.839546Z","shell.execute_reply":"2025-04-05T12:57:57.839354Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3 - Calcolare le curve ROC e AUC per entrambe le probabilità (logistic e SVM)\n\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\n# svolgimento...\nfpr_r, tpr_r, thresholds_r = roc_curve(y_test, y_pred_prob_reg)\nfpr_s, tpr_s, thresholds_s = roc_curve(y_test, y_pred_proba_svm)\nauc_r = roc_auc_score(y_test,y_pred_prob_reg)\nauc_s = roc_auc_score(y_test,y_pred_proba_svm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.840398Z","iopub.status.idle":"2025-04-05T12:57:57.840822Z","shell.execute_reply":"2025-04-05T12:57:57.840635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4 - Disegnare le curve ROC per entrambe le probabilità (logistic e SVM)\n\ndef plot_roc_curve(fpr, tpr, auc):\n    \"\"\"\n    Disegna la curva ROC e stampa il valore AUC.\n\n    Parameters:\n    -----------\n    fpr : array-like\n        Tasso di falsi positivi (False Positive Rate).\n    tpr : array-like\n        Tasso di veri positivi (True Positive Rate).\n    auc : float\n        Area sotto la curva (AUC).\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    plt.figure(figsize=(6, 4))\n    plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {auc:.4f}')\n    plt.plot([0, 1], [0, 1], color='red', linestyle='--', lw=2)  # Linea di non discriminazione\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc='lower right')\n    plt.grid()\n    plt.show()\n\n    # Stampa il valore AUC\n    print(f\"AUC: {auc:.4f}\")\n\n# svolgimento...\nplot_roc_curve(fpr_r, tpr_r, auc_r)\nplot_roc_curve(fpr_s, tpr_s, auc_s)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.841751Z","iopub.status.idle":"2025-04-05T12:57:57.842199Z","shell.execute_reply":"2025-04-05T12:57:57.842008Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Esercizio 4: Classificazione multi classe**\n\nSe finora abbiamo lavorato soltanto con classificazione binaria, adesso addestriamo nuovamente i classificatori visti sopra, ma nella situazione in cui abbiamo più classi. ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\n\n\nmnist = fetch_openml('mnist_784', version=1, parser='auto')\nX, y = np.array(mnist.data), np.array(mnist.target.astype(int))\n\n# Utilizziamo soltanto il 20% dei campioni del dataset per questioni di praticità\nn_percent = 0.2  \n\n# La funzione train_test_split ci assicura che i dati che rimuoviamo siano bilanciati.\n# In questo modo non alteriamo la distribuzione delle classi.\nX, _, y, _ = train_test_split(\n    X, y, train_size=n_percent, stratify=y, random_state=42\n)\n\nX, y = shuffle(X, y)\n\nprint(\"Shape of X:\", X.shape)\nprint(\"Shape of y:\", y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.843028Z","iopub.status.idle":"2025-04-05T12:57:57.843482Z","shell.execute_reply":"2025-04-05T12:57:57.843293Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1 - Dividiamo il dataset in train, validation e test e standardizziamo.\ntrain_fraction = 0.6  \nvalidation_fraction = 0.2  \ntest_fraction = 0.2  \n\n\n# svolgimento...\nnum_train = int(train_fraction * X.shape[0])\nnum_validation = int(validation_fraction * X.shape[0])\nX_train = X[:num_train]\ny_train = y[:num_train]\nX_validation = X[num_train:num_train + num_validation]\ny_validation = y[num_train:num_train + num_validation]\nX_test = X[num_train + num_validation:]\ny_test = y[num_train + num_validation:]\n\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_validation = scaler.transform(X_validation)\nX_test = scaler.transform(X_test)\n\nprint(\"Train set:\", X_train.shape)\nprint(\"Validation set:\", X_validation.shape)\nprint(\"Test set:\", X_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.844425Z","iopub.status.idle":"2025-04-05T12:57:57.844862Z","shell.execute_reply":"2025-04-05T12:57:57.844670Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2 - Alleniamo il modello di regressione logistica e calcoliamo le predizioni e prestazioni.\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\n\n# IMPORTANTE:\n# Quando istanziamo la classe LogisticRegression utilizziamo come parametri\n# max_iter=200 e solver='lbfgs'.\n\n# svolgimento...\nmodello = LogisticRegression(max_iter = 1000, solver = 'lbfgs')\nmodello.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.845873Z","iopub.status.idle":"2025-04-05T12:57:57.846337Z","shell.execute_reply":"2025-04-05T12:57:57.846126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3 - Alleniamo il modello di SVM e calcoliamo le predizioni e prestazioni.\nfrom sklearn.svm import SVC\n\n# IMPORTANTE:\n# Quando istanziamo la classe SVC utilizziamo come parametri C=0.01, \n# kernel='linear' e decision_function_shape='ovr'.\n\n# svolgimento...\nmodello= SVC (C=0.01, kernel='linear', decision_function_shape='ovr', random_state=42)\nmodello.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.847597Z","iopub.status.idle":"2025-04-05T12:57:57.848042Z","shell.execute_reply":"2025-04-05T12:57:57.847841Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Esercizio 5: Scrivere una funzione pipeline per l' allenamento di un classificatore**\n\nLa funzione `pipeline` prende in input il train set, `X_train` e `y_train`, il validation set, `X_val` e `y_val`, e un dizionario `hyperparams` che contiene una configurazione di training.\n\nLa funzione deve:\n\n* Applicare la PCA **se richiesto**.\n\n* Standardizzare i dati **a prescindere che sia richiesto o meno**.\n\n* Allenare un classificatore. Il dizionario avrà una chiave `classifier`, il cui value può essere:\n\n    * `lr` per indicare un modello di **Regressione Logistica**.\n    * `svm` per indicare un modello **SVM**. \n\n* Effettuare le predizioni e utilizzarle per calcolare l' accuracy del classificatore.","metadata":{}},{"cell_type":"code","source":"# IMPORTANTE: Eseguire questa cella prima di procedere\n\ndef plot_confusion_matrix_multiclass(cm):\n    \"\"\"\n    Visualizza una matrice di confusione come heatmap.\n\n    Parameters:\n    -----------\n    cm : numpy.ndarray\n        La matrice di confusione da visualizzare\n    \"\"\"\n    # Calcola dinamicamente le etichette delle classi\n    class_labels = [f\"Class {i}\" for i in range(cm.shape[0])]\n    \n    # Visualizza la heatmap\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_labels, yticklabels=class_labels)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.849073Z","iopub.status.idle":"2025-04-05T12:57:57.849443Z","shell.execute_reply":"2025-04-05T12:57:57.849314Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ndef pipeline(X_train, y_train, X_val, y_val, hyperparams):\n    \n    if hyperparams['use_pca']:\n        \n        # Implementare codice per la PCA\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_val = scaler.transform(X_val)\n    pca = PCA()\n    X_train = pca.fit_transform(X_train)\n    X_val = pca.transform(X_val)\n        \n    # Implementare codice per la standardizzazione\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_val = scalr.transform(X_val)\n    \n    if hyperparams['classifier'] == 'lr':  \n        # Implementare codice per Regressione Lineare\n    modello = logisticRegression(max_iter = 100, solver = 'liblinear', C = 1.0)\n    modello.fit(X_train, y_train)\n        \n    elif hyperparams['classifier'] == 'svm':  \n        # Implementare codice per SVM\n    modello_svm = SVC(kernel = 'linear', C = 1.0)\n    modello_svm.fit(X_train, y_train)\n        \n    # Effettuare predizioni\n    predizioni_val = modello_svm.predict(X_val)\n    # Calcolare e stampare accuracy sul validation set \n    val_correct = sum (predizioni_val == y_val)\n    tot_val = len(y_val)\n    val_acc = val_correct / tot_val if tot_val > 0 else 0\n    \n    # Calcolare la matrice di confusione\n    cm = confusion_matrix(y_val, predizioni_val)\n    # Visualizzare la matrice di confusione\n    plot_confusion_matrix_multiclass(cm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.850295Z","iopub.status.idle":"2025-04-05T12:57:57.850611Z","shell.execute_reply":"2025-04-05T12:57:57.850489Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Provare la funzione pipeline su tutte le configurazioni presenti qui di seguito\n\nhyperparams_1 = {\n    'use_pca': False,  \n    'classifier': 'svm',  \n}\n\nhyperparams_2 = {\n    'use_pca': True,  \n    'classifier': 'svm',  \n}\n\nhyperparams_3 = {\n    'use_pca': False,  \n    'classifier': 'lr',  \n}\n\nhyperparams_4 = {\n    'use_pca': True,  \n    'classifier': 'lr',  \n}\n\n# svolgimento...\npipeline(X_train, y_train, X_validation, y_validation, hyperparams_1)\npipeline(X_train, y_train, X_validation, y_validation, hyperparams_2)\npipeline(X_train, y_train, X_validation, y_validation, hyperparams_3)\npipeline(X_train, y_train, X_validation, y_validation, hyperparams_4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:57:57.851548Z","iopub.status.idle":"2025-04-05T12:57:57.851902Z","shell.execute_reply":"2025-04-05T12:57:57.851759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}